Metadata-Version: 2.1
Name: llm-bedrock-anthropic
Version: 0.4.2
Summary: LLM plugin for Anthropic's Claude on AWS Bedrock
Author: Sean Blakey, Will Sorenson
License: Apache-2.0
Project-URL: Homepage, https://github.com/sblakey/llm-bedrock-anthropic
Classifier: License :: OSI Approved :: Apache Software License
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: llm
Requires-Dist: boto3>=1.34.55
Requires-Dist: pydantic>=2.0

# llm-bedrock-anthropic

[![PyPI](https://img.shields.io/pypi/v/llm-bedrock-anthropic.svg)](https://pypi.org/project/llm-bedrock-anthropic/)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/sblakey/llm-bedrock-anthropic/blob/main/LICENSE)

Plugin for [LLM](https://llm.datasette.io/) adding support for Anthropic's Claude models.

## New: claude opus model 
### claude-3-opus available on us-west-2

## Installation

Install this plugin in the same environment as LLM. From the current directory
```bash
llm install llm-bedrock-anthropic
```
## Configuration

You will need to specify AWS Configuration with the normal boto3 and environment variables.

For example, to use the region `us-west-2` and AWS credentials under the `personal` profile, set the environment variables

```bash
export AWS_DEFAULT_REGION=us-west-2
export AWS_PROFILE=personal
```

## Usage

This plugin adds models called `bedrock-claude` and `bedrock-claude-instant`.

You can query them like this:

```bash
llm -m bedrock-claude-instant "Ten great names for a new space station"
```

```bash
llm -m bedrock-claude "Compare and contrast the leadership styles of Abraham Lincoln and Boris Johnson."
```

## Options

- `max_tokens_to_sample`, default 8_191: The maximum number of tokens to generate before stopping

Use like this:
```bash
llm -m bedrock-claude -o max_tokens_to_sample 20 "Sing me the alphabet"
 Here is the alphabet song:

A B C D E F G
H I J
```
